{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset (Single Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.2527795 , 0.08312264, 0.7228865 , 0.21066908, 0.26303798,\n",
       "       0.95288637, 0.00670555, 0.58455555, 0.51714767, 0.67176602])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(low = 0.0, high = 1.0, size = 100)\n",
    "print (x.shape)\n",
    "x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07583385, 0.02493679, 0.21686595, 0.06320072, 0.07891139,\n",
       "       0.28586591, 0.00201167, 0.17536666, 0.1551443 , 0.20152981])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * 0.3\n",
    "print (y.shape)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 0.002385, error = 0.150516\n",
      " 1 w = 0.470284, error = 0.086120\n",
      " 3 w = 0.461673, error = 0.081765\n",
      " 5 w = 0.357468, error = 0.029064\n",
      "11 w = 0.262428, error = 0.019002\n",
      "16 w = 0.320009, error = 0.010119\n",
      "26 w = 0.290669, error = 0.004719\n",
      "----------------------------------------\n",
      "26 w = 0.290669, error = 0.004719\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "best_error = np.inf\n",
    "best_w = None\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    w = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    y_predict = x * w\n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_w = w\n",
    "        best_epoch = epoch\n",
    "        print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, error))\n",
    "\n",
    "print (\"----\" * 10)\n",
    "print (\"{:2} w = {:.6f}, error = {:.6f}\".format(best_epoch, best_w, best_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2 H-Step Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 0.384552, error = 0.007813\n",
      "----------------------------------------\n",
      " 1 w = 0.284552, error = 0.007813\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "h = 0.1\n",
    "\n",
    "w = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = x * w\n",
    "    current_error = np.abs(y_predict - y).mean()\n",
    "    \n",
    "    y_predict = x * (w + h)\n",
    "    h_plus_error = np.abs(y_predict - y).mean()\n",
    "    if h_plus_error < current_error:\n",
    "        print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, h_plus_error)) \n",
    "        w = w + h\n",
    "        continue\n",
    "    \n",
    "    y_predict = x * (w - h)\n",
    "    h_minus_error = np.abs(y_predict - y).mean()\n",
    "    if h_minus_error < current_error:\n",
    "        print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, h_minus_error)) \n",
    "        w = w - h\n",
    "        continue\n",
    "        \n",
    "    break\n",
    "\n",
    "print (\"----\" * 10)\n",
    "print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, current_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 - Gradient Descent (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 w = 0.381490, error = 0.041213\n",
      " 1 w = 0.340277, error = 0.020370\n",
      " 2 w = 0.319907, error = 0.010068\n",
      " 3 w = 0.309839, error = 0.004976\n",
      " 4 w = 0.304863, error = 0.002460\n",
      " 5 w = 0.302404, error = 0.001216\n",
      " 6 w = 0.301188, error = 0.000601\n",
      "----------------------------------------\n",
      " 7 w = 0.300587, error = 0.007813\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "w = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = x * w\n",
    "\n",
    "    error = np.abs(y_predict - y).mean()    \n",
    "    if error < 0.0005:\n",
    "        break\n",
    "    \n",
    "    print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, error))\n",
    "    \n",
    "    w = w - (y_predict - y).mean()\n",
    "    ### w가 미세하게 바뀔 수 있다.\n",
    "    ### np.abs(y_predict - y).mean()은 error의 크기만 보는 것이고\n",
    "    ### (y_predict - y).mean()는 방향성만 고려하는 것이다.\n",
    "\n",
    "print (\"----\" * 10)\n",
    "print (\"{:2} w = {:.6f}, error = {:.6f}\".format(epoch, w, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset (Multi Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.93136816, 0.92819147, 0.70146286, 0.89644403, 0.46976151,\n",
       "       0.73058125, 0.91121839, 0.20314373, 0.44743208, 0.27513544])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.uniform(low = 0.0, high = 1.0, size = 100)\n",
    "print (x1.shape)\n",
    "x1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87580484, 0.92753513, 0.31718843, 0.40265446, 0.68044304,\n",
       "       0.30432413, 0.95735766, 0.47498527, 0.50854411, 0.23425251])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.random.uniform(low = 0.0, high = 1.0, size = 100)\n",
    "print (x2.shape)\n",
    "x2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71731287, 0.742225  , 0.36903307, 0.47026044, 0.48114997,\n",
       "       0.37133644, 0.75204435, 0.29843575, 0.38850168, 0.19966689])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x1 * 0.3 + x2 * 0.5\n",
    "print (y.shape)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 w1 = 0.978938, w2 = 0.847022, error = 0.480984\n",
      "   1 w1 = 0.459028, w2 = 0.756259, error = 0.195734\n",
      "   2 w1 = 0.366621, w2 = 0.459004, error = 0.019231\n",
      "  92 w1 = 0.328135, w2 = 0.500232, error = 0.013214\n",
      " 442 w1 = 0.296987, w2 = 0.512269, error = 0.004795\n",
      "1399 w1 = 0.299216, w2 = 0.498556, error = 0.001051\n",
      "------------------------------------------------------------\n",
      "1399 w1 = 0.299216, w2 = 0.498556, error = 0.001051\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10000\n",
    "\n",
    "best_error = np.inf\n",
    "best_w1 = None\n",
    "best_w2 = None\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    w1 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    w2 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    \n",
    "    y_predict = x1 * w1 + x2 * w2\n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_w1 = w1\n",
    "        best_w2 = w2\n",
    "        best_epoch = epoch\n",
    "        print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, error))\n",
    "\n",
    "print (\"----\" * 15)\n",
    "print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, error = {:.6f}\".format(best_epoch, best_w1, best_w2, best_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 - Gradient Descent (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 w1 = 0.054941, w2 = 0.005076, error = 0.349117\n",
      "   1 w1 = 0.238200, w2 = 0.218068, error = 0.162638\n",
      "   2 w1 = 0.320180, w2 = 0.321689, error = 0.076631\n",
      "   3 w1 = 0.354954, w2 = 0.373735, error = 0.043433\n",
      "   4 w1 = 0.367862, w2 = 0.401334, error = 0.030691\n",
      "   5 w1 = 0.370770, w2 = 0.417228, error = 0.025159\n",
      "   6 w1 = 0.369222, w2 = 0.427411, error = 0.022191\n",
      "   7 w1 = 0.365802, w2 = 0.434712, error = 0.020259\n",
      "   8 w1 = 0.361705, w2 = 0.440472, error = 0.018688\n",
      "   9 w1 = 0.357478, w2 = 0.445335, error = 0.017266\n",
      "  10 w1 = 0.353361, w2 = 0.449616, error = 0.015981\n",
      "  11 w1 = 0.349456, w2 = 0.453474, error = 0.014789\n",
      "  12 w1 = 0.345798, w2 = 0.456995, error = 0.013685\n",
      "  13 w1 = 0.342393, w2 = 0.460231, error = 0.012662\n",
      "  14 w1 = 0.339232, w2 = 0.463214, error = 0.011716\n",
      "  15 w1 = 0.336302, w2 = 0.465969, error = 0.010840\n",
      "  16 w1 = 0.333590, w2 = 0.468515, error = 0.010030\n",
      "  17 w1 = 0.331079, w2 = 0.470870, error = 0.009280\n",
      "  18 w1 = 0.328756, w2 = 0.473049, error = 0.008586\n",
      "  19 w1 = 0.326606, w2 = 0.475064, error = 0.007944\n",
      "  20 w1 = 0.324617, w2 = 0.476929, error = 0.007350\n",
      "  21 w1 = 0.322776, w2 = 0.478654, error = 0.006800\n",
      "  22 w1 = 0.321073, w2 = 0.480250, error = 0.006292\n",
      "  23 w1 = 0.319498, w2 = 0.481727, error = 0.005821\n",
      "  24 w1 = 0.318040, w2 = 0.483093, error = 0.005386\n",
      "  25 w1 = 0.316691, w2 = 0.484357, error = 0.004983\n",
      "  26 w1 = 0.315443, w2 = 0.485527, error = 0.004611\n",
      "  27 w1 = 0.314288, w2 = 0.486609, error = 0.004266\n",
      "  28 w1 = 0.313220, w2 = 0.487610, error = 0.003947\n",
      "  29 w1 = 0.312231, w2 = 0.488537, error = 0.003652\n",
      "  30 w1 = 0.311317, w2 = 0.489394, error = 0.003379\n",
      "  31 w1 = 0.310471, w2 = 0.490187, error = 0.003126\n",
      "  32 w1 = 0.309688, w2 = 0.490921, error = 0.002892\n",
      "  33 w1 = 0.308963, w2 = 0.491599, error = 0.002676\n",
      "  34 w1 = 0.308293, w2 = 0.492228, error = 0.002476\n",
      "  35 w1 = 0.307673, w2 = 0.492809, error = 0.002291\n",
      "  36 w1 = 0.307099, w2 = 0.493346, error = 0.002120\n",
      "  37 w1 = 0.306569, w2 = 0.493844, error = 0.001961\n",
      "  38 w1 = 0.306077, w2 = 0.494304, error = 0.001815\n",
      "  39 w1 = 0.305623, w2 = 0.494730, error = 0.001679\n",
      "  40 w1 = 0.305203, w2 = 0.495124, error = 0.001553\n",
      "  41 w1 = 0.304814, w2 = 0.495489, error = 0.001437\n",
      "  42 w1 = 0.304454, w2 = 0.495826, error = 0.001330\n",
      "  43 w1 = 0.304121, w2 = 0.496138, error = 0.001230\n",
      "  44 w1 = 0.303813, w2 = 0.496427, error = 0.001138\n",
      "  45 w1 = 0.303527, w2 = 0.496694, error = 0.001053\n",
      "  46 w1 = 0.303264, w2 = 0.496941, error = 0.000974\n",
      "  47 w1 = 0.303020, w2 = 0.497170, error = 0.000902\n",
      "  48 w1 = 0.302794, w2 = 0.497382, error = 0.000834\n",
      "  49 w1 = 0.302585, w2 = 0.497577, error = 0.000772\n",
      "  50 w1 = 0.302392, w2 = 0.497758, error = 0.000714\n",
      "  51 w1 = 0.302213, w2 = 0.497926, error = 0.000661\n",
      "  52 w1 = 0.302047, w2 = 0.498081, error = 0.000611\n",
      "  53 w1 = 0.301894, w2 = 0.498225, error = 0.000566\n",
      "  54 w1 = 0.301753, w2 = 0.498357, error = 0.000523\n",
      "------------------------------------------------------------\n",
      "  55 w1 = 0.301622, w2 = 0.498480, error = 0.000484\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10000\n",
    "\n",
    "w1 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "w2 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = x1 * w1 + x2 * w2\n",
    "\n",
    "    error = np.abs(y_predict - y).mean()    \n",
    "    if error < 0.0005:\n",
    "        break\n",
    "    \n",
    "    print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, error))\n",
    "    \n",
    "    w1 = w1 - ((y_predict - y) * x1).mean()\n",
    "    w2 = w2 - ((y_predict - y) * x2).mean()\n",
    "    ### w1, w2는 서로 변화량이 달라야 한다.\n",
    "    ### ((y_predict - y) * x1).mean(), ((y_predict - y) * x2).mean()를 이용하여\n",
    "    ### feature 각각의 방향성을 고려한다.\n",
    "    \n",
    "print (\"----\" * 15)\n",
    "print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset (Multi Feature with Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22601894, 0.6801539 , 0.9999859 , 0.81228367, 0.49599131,\n",
       "       0.06851541, 0.12002865, 0.30363821, 0.15674128, 0.50746203])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.uniform(low = 0.0, high = 1.0, size = 100)\n",
    "print (x1.shape)\n",
    "x1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70781306, 0.16217993, 0.06675143, 0.89816791, 0.82571392,\n",
       "       0.3286649 , 0.63916029, 0.42216842, 0.38749287, 0.66821074])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.random.uniform(low = 0.0, high = 1.0, size = 100)\n",
    "print (x2.shape)\n",
    "x2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.52171221, 0.38513613, 0.43337149, 0.79276906, 0.66165435,\n",
       "       0.28488707, 0.45558874, 0.40217567, 0.34076882, 0.58634398])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x1 * 0.3 + x2 * 0.5 + 0.1\n",
    "print (y.shape)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 w1 = 0.809140, w2 = 0.143510, b = 0.038143, error = 0.139998\n",
      "    2 w1 = 0.050794, w2 = 0.249944, b = 0.433936, error = 0.114073\n",
      "    8 w1 = 0.075005, w2 = 0.284312, b = 0.253189, error = 0.098476\n",
      "   20 w1 = 0.136782, w2 = 0.379042, b = 0.173935, error = 0.078548\n",
      "   22 w1 = 0.082519, w2 = 0.762838, b = 0.074151, error = 0.077366\n",
      "   32 w1 = 0.471155, w2 = 0.490632, b = 0.039703, error = 0.045104\n",
      "  291 w1 = 0.262817, w2 = 0.666132, b = 0.026999, error = 0.041223\n",
      "  295 w1 = 0.420787, w2 = 0.582119, b = 0.001760, error = 0.037655\n",
      "  621 w1 = 0.289837, w2 = 0.586452, b = 0.097924, error = 0.037503\n",
      "  997 w1 = 0.359268, w2 = 0.491795, b = 0.086753, error = 0.017153\n",
      " 3582 w1 = 0.292333, w2 = 0.436705, b = 0.133794, error = 0.016876\n",
      " 5618 w1 = 0.234082, w2 = 0.517503, b = 0.119801, error = 0.016755\n",
      " 6291 w1 = 0.323191, w2 = 0.453610, b = 0.110656, error = 0.012122\n",
      " 8695 w1 = 0.314640, w2 = 0.460449, b = 0.106147, error = 0.011646\n",
      "13628 w1 = 0.311064, w2 = 0.533442, b = 0.079245, error = 0.009573\n",
      "24556 w1 = 0.305333, w2 = 0.530323, b = 0.080502, error = 0.008166\n",
      "89813 w1 = 0.299734, w2 = 0.510338, b = 0.102274, error = 0.007409\n",
      "--------------------------------------------------------------------------------\n",
      "89813 w1 = 0.299734, w2 = 0.510338, b = 0.102274, error = 0.007409\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100000\n",
    "\n",
    "best_error = np.inf\n",
    "best_w1 = None\n",
    "best_w2 = None\n",
    "best_b = None\n",
    "best_epoch = None\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    w1 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    w2 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    b = np.random.uniform(low = 0.0, high = 1.0)\n",
    "    \n",
    "    y_predict = x1 * w1 + x2 * w2 + b\n",
    "    error = np.abs(y_predict - y).mean()\n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_w1 = w1\n",
    "        best_w2 = w2\n",
    "        best_b = b\n",
    "        best_epoch = epoch\n",
    "        print (\"{:5} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, b, error))\n",
    "\n",
    "print (\"----\" * 20)\n",
    "print (\"{:5} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(best_epoch, best_w1, best_w2, best_b, best_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 - Gradient Descent (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = [1] * 100\n",
    "x3 = np.array(x3)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 w1 = 0.002931, w2 = 0.303485, b = 0.357255, error = 0.092982\n",
      "   1 w1 = 0.028570, w2 = 0.321852, b = 0.352742, error = 0.087647\n",
      "   2 w1 = 0.042528, w2 = 0.329126, b = 0.330211, error = 0.081640\n",
      "   3 w1 = 0.061181, w2 = 0.341542, b = 0.319335, error = 0.076624\n",
      "   4 w1 = 0.075493, w2 = 0.350087, b = 0.303426, error = 0.071634\n",
      "   5 w1 = 0.090627, w2 = 0.359860, b = 0.291720, error = 0.067142\n",
      "   6 w1 = 0.103802, w2 = 0.368065, b = 0.278966, error = 0.062837\n",
      "   7 w1 = 0.116670, w2 = 0.376319, b = 0.268017, error = 0.058861\n",
      "   8 w1 = 0.128399, w2 = 0.383767, b = 0.257201, error = 0.055107\n",
      "   9 w1 = 0.139539, w2 = 0.390934, b = 0.247380, error = 0.051610\n",
      "  10 w1 = 0.149862, w2 = 0.397571, b = 0.238006, error = 0.048325\n",
      "  11 w1 = 0.159570, w2 = 0.403858, b = 0.229321, error = 0.045255\n",
      "  12 w1 = 0.168620, w2 = 0.409734, b = 0.221130, error = 0.042377\n",
      "  13 w1 = 0.177101, w2 = 0.415268, b = 0.213488, error = 0.039684\n",
      "  14 w1 = 0.185024, w2 = 0.420457, b = 0.206311, error = 0.037163\n",
      "  15 w1 = 0.192439, w2 = 0.425335, b = 0.199597, error = 0.034803\n",
      "  16 w1 = 0.199372, w2 = 0.429913, b = 0.193302, error = 0.032593\n",
      "  17 w1 = 0.205859, w2 = 0.434213, b = 0.187408, error = 0.030523\n",
      "  18 w1 = 0.211925, w2 = 0.438251, b = 0.181884, error = 0.028585\n",
      "  19 w1 = 0.217600, w2 = 0.442043, b = 0.176710, error = 0.026770\n",
      "  20 w1 = 0.222908, w2 = 0.445603, b = 0.171863, error = 0.025070\n",
      "  21 w1 = 0.227873, w2 = 0.448946, b = 0.167322, error = 0.023479\n",
      "  22 w1 = 0.232518, w2 = 0.452084, b = 0.163068, error = 0.021988\n",
      "  23 w1 = 0.236862, w2 = 0.455031, b = 0.159083, error = 0.020592\n",
      "  24 w1 = 0.240926, w2 = 0.457798, b = 0.155349, error = 0.019285\n",
      "  25 w1 = 0.244728, w2 = 0.460395, b = 0.151852, error = 0.018061\n",
      "  26 w1 = 0.248284, w2 = 0.462834, b = 0.148575, error = 0.016914\n",
      "  27 w1 = 0.251612, w2 = 0.465123, b = 0.145506, error = 0.015841\n",
      "  28 w1 = 0.254724, w2 = 0.467272, b = 0.142630, error = 0.014835\n",
      "  29 w1 = 0.257636, w2 = 0.469289, b = 0.139937, error = 0.013894\n",
      "  30 w1 = 0.260360, w2 = 0.471182, b = 0.137413, error = 0.013012\n",
      "  31 w1 = 0.262908, w2 = 0.472959, b = 0.135049, error = 0.012186\n",
      "  32 w1 = 0.265292, w2 = 0.474628, b = 0.132834, error = 0.011413\n",
      "  33 w1 = 0.267523, w2 = 0.476194, b = 0.130759, error = 0.010689\n",
      "  34 w1 = 0.269609, w2 = 0.477663, b = 0.128815, error = 0.010010\n",
      "  35 w1 = 0.271562, w2 = 0.479043, b = 0.126994, error = 0.009375\n",
      "  36 w1 = 0.273389, w2 = 0.480337, b = 0.125288, error = 0.008780\n",
      "  37 w1 = 0.275098, w2 = 0.481552, b = 0.123690, error = 0.008223\n",
      "  38 w1 = 0.276697, w2 = 0.482693, b = 0.122193, error = 0.007702\n",
      "  39 w1 = 0.278193, w2 = 0.483763, b = 0.120791, error = 0.007213\n",
      "  40 w1 = 0.279593, w2 = 0.484767, b = 0.119477, error = 0.006755\n",
      "  41 w1 = 0.280902, w2 = 0.485709, b = 0.118246, error = 0.006327\n",
      "  42 w1 = 0.282128, w2 = 0.486594, b = 0.117093, error = 0.005926\n",
      "  43 w1 = 0.283275, w2 = 0.487424, b = 0.116013, error = 0.005550\n",
      "  44 w1 = 0.284347, w2 = 0.488202, b = 0.115001, error = 0.005198\n",
      "  45 w1 = 0.285351, w2 = 0.488933, b = 0.114053, error = 0.004868\n",
      "  46 w1 = 0.286291, w2 = 0.489619, b = 0.113165, error = 0.004559\n",
      "  47 w1 = 0.287170, w2 = 0.490262, b = 0.112333, error = 0.004270\n",
      "  48 w1 = 0.287992, w2 = 0.490866, b = 0.111553, error = 0.003999\n",
      "  49 w1 = 0.288762, w2 = 0.491432, b = 0.110823, error = 0.003746\n",
      "  50 w1 = 0.289482, w2 = 0.491963, b = 0.110139, error = 0.003508\n",
      "  51 w1 = 0.290156, w2 = 0.492462, b = 0.109498, error = 0.003286\n",
      "  52 w1 = 0.290787, w2 = 0.492930, b = 0.108898, error = 0.003077\n",
      "  53 w1 = 0.291377, w2 = 0.493368, b = 0.108336, error = 0.002882\n",
      "  54 w1 = 0.291930, w2 = 0.493780, b = 0.107809, error = 0.002699\n",
      "  55 w1 = 0.292447, w2 = 0.494166, b = 0.107315, error = 0.002528\n",
      "  56 w1 = 0.292930, w2 = 0.494529, b = 0.106853, error = 0.002368\n",
      "  57 w1 = 0.293383, w2 = 0.494868, b = 0.106420, error = 0.002218\n",
      "  58 w1 = 0.293807, w2 = 0.495187, b = 0.106014, error = 0.002077\n",
      "  59 w1 = 0.294203, w2 = 0.495486, b = 0.105634, error = 0.001946\n",
      "  60 w1 = 0.294574, w2 = 0.495767, b = 0.105278, error = 0.001822\n",
      "  61 w1 = 0.294921, w2 = 0.496030, b = 0.104945, error = 0.001707\n",
      "  62 w1 = 0.295246, w2 = 0.496277, b = 0.104632, error = 0.001599\n",
      "  63 w1 = 0.295550, w2 = 0.496509, b = 0.104339, error = 0.001497\n",
      "  64 w1 = 0.295835, w2 = 0.496726, b = 0.104065, error = 0.001402\n",
      "  65 w1 = 0.296101, w2 = 0.496930, b = 0.103808, error = 0.001313\n",
      "  66 w1 = 0.296351, w2 = 0.497121, b = 0.103567, error = 0.001230\n",
      "  67 w1 = 0.296584, w2 = 0.497300, b = 0.103342, error = 0.001152\n",
      "  68 w1 = 0.296803, w2 = 0.497468, b = 0.103131, error = 0.001079\n",
      "  69 w1 = 0.297007, w2 = 0.497626, b = 0.102933, error = 0.001011\n",
      "  70 w1 = 0.297198, w2 = 0.497774, b = 0.102748, error = 0.000947\n",
      "  71 w1 = 0.297377, w2 = 0.497912, b = 0.102574, error = 0.000887\n",
      "  72 w1 = 0.297545, w2 = 0.498042, b = 0.102411, error = 0.000831\n",
      "  73 w1 = 0.297702, w2 = 0.498164, b = 0.102259, error = 0.000778\n",
      "  74 w1 = 0.297849, w2 = 0.498279, b = 0.102116, error = 0.000729\n",
      "  75 w1 = 0.297986, w2 = 0.498386, b = 0.101982, error = 0.000682\n",
      "  76 w1 = 0.298115, w2 = 0.498487, b = 0.101857, error = 0.000639\n",
      "  77 w1 = 0.298235, w2 = 0.498581, b = 0.101740, error = 0.000599\n",
      "  78 w1 = 0.298348, w2 = 0.498670, b = 0.101630, error = 0.000561\n",
      "  79 w1 = 0.298453, w2 = 0.498753, b = 0.101527, error = 0.000525\n",
      "------------------------------------------------------------\n",
      "  80 w1 = 0.298552, w2 = 0.498830, b = 0.101430, error = 0.000492\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "\n",
    "w1 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "w2 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "b = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = x1 * w1 + x2 * w2 + x3 * b\n",
    "\n",
    "    error = np.abs(y_predict - y).mean()    \n",
    "    if error < 0.0005:\n",
    "        break\n",
    "    \n",
    "    print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, b, error))\n",
    "    \n",
    "    w1 = w1 - ((y_predict - y) * x1).mean()\n",
    "    w2 = w2 - ((y_predict - y) * x2).mean()\n",
    "    b = b - (y_predict - y).mean()\n",
    "    ### bias는 해당 feature가 모두 1이라고 가정 할 수 있다.\n",
    "    ### ((y_predict - y) * x3).mean()\n",
    "    ### 1을 곱하는 것은 생략해도 되므로 (y_predict - y).mean()로 방향성을 고려한다.\n",
    "    \n",
    "print (\"----\" * 15)\n",
    "print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, b, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 - Gradient Descent with Hyperparmeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 w1 = 0.676730, w2 = 0.282931, b = 0.422228, error = 0.404995\n",
      "   1 w1 = 0.391493, w2 = 0.052156, b = -0.063766, error = 0.345134\n",
      "   2 w1 = 0.601307, w2 = 0.308545, b = 0.350395, error = 0.307493\n",
      "   3 w1 = 0.383556, w2 = 0.135875, b = -0.018597, error = 0.261353\n",
      "   4 w1 = 0.541333, w2 = 0.332415, b = 0.295027, error = 0.233500\n",
      "   5 w1 = 0.375013, w2 = 0.203418, b = 0.014827, error = 0.197877\n",
      "   6 w1 = 0.493564, w2 = 0.354223, b = 0.252279, error = 0.177343\n",
      "   7 w1 = 0.366457, w2 = 0.258022, b = 0.039468, error = 0.149856\n",
      "   8 w1 = 0.455456, w2 = 0.373852, b = 0.219213, error = 0.134718\n",
      "   9 w1 = 0.358258, w2 = 0.302252, b = 0.057552, error = 0.113688\n",
      "  10 w1 = 0.425007, w2 = 0.391315, b = 0.193586, error = 0.102360\n",
      "  11 w1 = 0.350633, w2 = 0.338146, b = 0.070755, error = 0.086558\n",
      "  12 w1 = 0.400641, w2 = 0.406710, b = 0.173682, error = 0.077792\n",
      "  13 w1 = 0.343693, w2 = 0.367330, b = 0.080331, error = 0.066195\n",
      "  14 w1 = 0.381114, w2 = 0.420178, b = 0.158186, error = 0.059222\n",
      "  15 w1 = 0.337477, w2 = 0.391100, b = 0.087221, error = 0.050720\n",
      "  16 w1 = 0.365443, w2 = 0.431889, b = 0.146094, error = 0.045166\n",
      "  17 w1 = 0.331981, w2 = 0.410492, b = 0.092131, error = 0.038963\n",
      "  18 w1 = 0.352850, w2 = 0.442019, b = 0.136634, error = 0.034562\n",
      "  19 w1 = 0.327170, w2 = 0.426339, b = 0.095584, error = 0.030149\n",
      "  20 w1 = 0.342717, w2 = 0.450744, b = 0.129211, error = 0.026524\n",
      "  21 w1 = 0.322993, w2 = 0.439309, b = 0.097974, error = 0.023567\n",
      "  22 w1 = 0.334555, w2 = 0.458230, b = 0.123372, error = 0.020442\n",
      "  23 w1 = 0.319392, w2 = 0.449939, b = 0.099591, error = 0.018508\n",
      "  24 w1 = 0.327972, w2 = 0.464634, b = 0.118763, error = 0.015812\n",
      "  25 w1 = 0.316305, w2 = 0.458664, b = 0.100650, error = 0.014596\n",
      "  26 w1 = 0.322658, w2 = 0.470097, b = 0.115115, error = 0.012342\n",
      "  27 w1 = 0.313672, w2 = 0.465835, b = 0.101312, error = 0.011588\n",
      "  28 w1 = 0.318363, w2 = 0.474746, b = 0.112217, error = 0.009701\n",
      "  29 w1 = 0.311436, w2 = 0.471736, b = 0.101693, error = 0.009271\n",
      "  30 w1 = 0.314890, w2 = 0.478695, b = 0.109909, error = 0.007667\n",
      "  31 w1 = 0.309544, w2 = 0.476597, b = 0.101879, error = 0.007443\n",
      "  32 w1 = 0.312079, w2 = 0.482043, b = 0.108063, error = 0.006099\n",
      "  33 w1 = 0.307948, w2 = 0.480606, b = 0.101932, error = 0.006008\n",
      "  34 w1 = 0.309801, w2 = 0.484877, b = 0.106583, error = 0.004887\n",
      "  35 w1 = 0.306606, w2 = 0.483916, b = 0.101897, error = 0.004862\n",
      "  36 w1 = 0.307955, w2 = 0.487272, b = 0.105391, error = 0.003931\n",
      "  37 w1 = 0.305481, w2 = 0.486651, b = 0.101808, error = 0.003944\n",
      "  38 w1 = 0.306458, w2 = 0.489295, b = 0.104428, error = 0.003179\n",
      "  39 w1 = 0.304540, w2 = 0.488914, b = 0.101685, error = 0.003215\n",
      "  40 w1 = 0.305243, w2 = 0.491001, b = 0.103648, error = 0.002590\n",
      "  41 w1 = 0.303755, w2 = 0.490787, b = 0.101546, error = 0.002627\n",
      "  42 w1 = 0.304257, w2 = 0.492439, b = 0.103014, error = 0.002126\n",
      "  43 w1 = 0.303100, w2 = 0.492340, b = 0.101401, error = 0.002150\n",
      "  44 w1 = 0.303456, w2 = 0.493649, b = 0.102497, error = 0.001752\n",
      "  45 w1 = 0.302556, w2 = 0.493627, b = 0.101257, error = 0.001763\n",
      "  46 w1 = 0.302805, w2 = 0.494668, b = 0.102073, error = 0.001450\n",
      "  47 w1 = 0.302104, w2 = 0.494695, b = 0.101120, error = 0.001447\n",
      "  48 w1 = 0.302276, w2 = 0.495524, b = 0.101726, error = 0.001202\n",
      "  49 w1 = 0.301730, w2 = 0.495581, b = 0.100991, error = 0.001190\n",
      "  50 w1 = 0.301847, w2 = 0.496244, b = 0.101439, error = 0.000998\n",
      "  51 w1 = 0.301420, w2 = 0.496318, b = 0.100872, error = 0.000980\n",
      "  52 w1 = 0.301498, w2 = 0.496849, b = 0.101203, error = 0.000829\n",
      "  53 w1 = 0.301164, w2 = 0.496931, b = 0.100764, error = 0.000807\n",
      "  54 w1 = 0.301214, w2 = 0.497357, b = 0.101008, error = 0.000690\n",
      "  55 w1 = 0.300953, w2 = 0.497440, b = 0.100668, error = 0.000666\n",
      "  56 w1 = 0.300984, w2 = 0.497783, b = 0.100845, error = 0.000574\n",
      "  57 w1 = 0.300779, w2 = 0.497864, b = 0.100581, error = 0.000551\n",
      "------------------------------------------------------------\n",
      "  58 w1 = 0.300796, w2 = 0.498141, b = 0.100710, error = 0.000479\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "learning_rate = 1.2 # Hyperparameter\n",
    "\n",
    "w1 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "w2 = np.random.uniform(low = 0.0, high = 1.0)\n",
    "b = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_predict = x1 * w1 + x2 * w2 + b\n",
    "\n",
    "    error = np.abs(y_predict - y).mean()    \n",
    "    if error < 0.0005:\n",
    "        break\n",
    "    \n",
    "    print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, b, error))\n",
    "    \n",
    "    w1 = w1 - learning_rate * ((y_predict - y) * x1).mean()\n",
    "    w2 = w2 - learning_rate * ((y_predict - y) * x2).mean()\n",
    "    b = b - learning_rate * (y_predict - y).mean()\n",
    "    ### bias는 해당 feature가 모두 1이라고 가정 할 수 있다.\n",
    "    ### ((y_predict - y) * x3).mean()\n",
    "    ### 1을 곱하는 것은 생략해도 되므로 (y_predict - y).mean()로 방향성을 고려한다.\n",
    "    \n",
    "print (\"----\" * 15)\n",
    "print (\"{:4} w1 = {:.6f}, w2 = {:.6f}, b = {:.6f}, error = {:.6f}\".format(epoch, w1, w2, b, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
